{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":31154,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# !pip install evaluate\n# !pip install -U transformers huggingface_hub\n# !pip install seqeval","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Imports","metadata":{}},{"cell_type":"code","source":"import random\nimport unicodedata\nfrom copy import deepcopy\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nfrom datasets import (\n    load_dataset, DatasetDict, Dataset,\n    Features, Sequence, ClassLabel, Value,\n    concatenate_datasets\n)\n\nimport evaluate\n\nfrom transformers import (\n    AutoTokenizer, AutoModelForTokenClassification,\n    DataCollatorForTokenClassification,\n    TrainingArguments, Trainer\n)\n\nfrom peft import LoraConfig, get_peft_model, TaskType","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Configuration\n","metadata":{}},{"cell_type":"code","source":"# Data (MasakhaNER 2.0 Yorùbá Parquet files on Hugging Face)\nparquet_urls = {\n    \"train\": \"https://huggingface.co/datasets/masakhane/masakhaner2/resolve/refs/convert/parquet/yor/train/0000.parquet\",\n    \"validation\": \"https://huggingface.co/datasets/masakhane/masakhaner2/resolve/refs/convert/parquet/yor/validation/0000.parquet\",\n    \"test\": \"https://huggingface.co/datasets/masakhane/masakhaner2/resolve/refs/convert/parquet/yor/test/0000.parquet\",\n}\n\nlabel_names = [\"O\",\"B-PER\",\"I-PER\",\"B-ORG\",\"I-ORG\",\"B-LOC\",\"I-LOC\",\"B-DATE\",\"I-DATE\"]\nid2label = {i: s for i, s in enumerate(label_names)}\nlabel2id = {s: i for i, s in enumerate(label_names)}\n\nenglish_fillers = [\"abeg\", \"please\", \"nah\", \"even\", \"sha\", \"well\", \"like\", \"maybe\"]\nO_ID = 0\n\nSEED = 42\nrandom.seed(SEED)\nnp.random.seed(SEED)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Load MasakhaNER 2.0 (Yorùbá)","metadata":{}},{"cell_type":"code","source":"ds = load_dataset(\"parquet\", data_files=parquet_urls)\nprint(ds)\n\nprint(\"labels:\", label_names)\nex = ds[\"train\"][0]\nprint(\"tokens:\", ex[\"tokens\"][:25])\nprint(\"ner ids:\", ex[\"ner_tags\"][:25])\nprint(\"ner tags:\", [label_names[i] for i in ex[\"ner_tags\"][:25]])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Robustness split: remove diacritics (NFD + drop Mn)","metadata":{}},{"cell_type":"code","source":"def strip_diacritics(token: str) -> str:\n    norm = unicodedata.normalize(\"NFD\", token)\n    return \"\".join(ch for ch in norm if unicodedata.category(ch) != \"Mn\")\n\ndef make_no_diacritics_split(split_ds):\n    new_rows = []\n    for ex in split_ds:\n        new_tokens = [strip_diacritics(t) for t in ex[\"tokens\"]]\n        new_rows.append({\"id\": ex[\"id\"], \"tokens\": new_tokens, \"ner_tags\": ex[\"ner_tags\"]})\n    return Dataset.from_list(new_rows)\n\nno_diac = DatasetDict({\n    \"validation_no_diac\": make_no_diacritics_split(ds[\"validation\"]),\n    \"test_no_diac\": make_no_diacritics_split(ds[\"test\"]),\n})\nprint(no_diac)\nprint(\"before:\", \" \".join(ds[\"validation\"][0][\"tokens\"][:12]))\nprint(\"after :\", \" \".join(no_diac[\"validation_no_diac\"][0][\"tokens\"][:12]))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Robustness split: light code-switch inserts (at O-tag positions)","metadata":{}},{"cell_type":"code","source":"def make_codeswitch_split(split_ds, p_insert=0.12, max_inserts_per_sent=3):\n    rows = []\n    for ex in split_ds:\n        toks, tags = ex[\"tokens\"], ex[\"ner_tags\"]\n        new_toks, new_tags = [], []\n        inserts = 0\n        for t, tag in zip(toks, tags):\n            new_toks.append(t); new_tags.append(tag)\n            if tag == O_ID and inserts < max_inserts_per_sent and random.random() < p_insert:\n                filler = random.choice(english_fillers)\n                new_toks.append(filler)\n                new_tags.append(O_ID)\n                inserts += 1\n        rows.append({\"id\": ex[\"id\"], \"tokens\": new_toks, \"ner_tags\": new_tags})\n    return Dataset.from_list(rows)\n\ncs = DatasetDict({\n    \"validation_cs\": make_codeswitch_split(ds[\"validation\"], p_insert=0.12),\n    \"test_cs\": make_codeswitch_split(ds[\"test\"], p_insert=0.12),\n})\nprint(cs)\nprint(\"example with inserts:\", \" \".join(cs[\"validation_cs\"][0][\"tokens\"][:30]))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Bundle all splits","metadata":{}},{"cell_type":"code","source":"all_splits = DatasetDict({\n    \"train\": ds[\"train\"],\n    \"validation\": ds[\"validation\"],\n    \"test\": ds[\"test\"],\n    \"validation_no_diac\": no_diac[\"validation_no_diac\"],\n    \"test_no_diac\": no_diac[\"test_no_diac\"],\n    \"validation_cs\": cs[\"validation_cs\"],\n    \"test_cs\": cs[\"test_cs\"],\n})\nall_splits","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Tokeniser and BIO alignment","metadata":{}},{"cell_type":"code","source":"tok = AutoTokenizer.from_pretrained(\"xlm-roberta-base\", use_fast=True)\nprint(tok.name_or_path, \"— num labels:\", len(label_names))\n\ndef tokenize_and_align(examples, label_col=\"ner_tags\"):\n    tokenized = tok(examples[\"tokens\"], is_split_into_words=True, truncation=True)\n    new_labels = []\n    for i, labels in enumerate(examples[label_col]):\n        word_ids = tokenized.word_ids(batch_index=i)  # map subword to original word index\n        aligned = []\n        prev_word = None\n        for wid in word_ids:\n            if wid is None:\n                aligned.append(-100)\n            elif wid != prev_word:\n                aligned.append(labels[wid])\n            else:\n                aligned.append(-100)\n            prev_word = wid\n        new_labels.append(aligned)\n    tokenized[\"labels\"] = new_labels\n    return tokenized\n\ntok_ds = DatasetDict({\n    \"train\": all_splits[\"train\"].map(tokenize_and_align, batched=True, remove_columns=[\"id\",\"tokens\",\"ner_tags\"]),\n    \"validation\": all_splits[\"validation\"].map(tokenize_and_align, batched=True, remove_columns=[\"id\",\"tokens\",\"ner_tags\"]),\n    \"test\": all_splits[\"test\"].map(tokenize_and_align, batched=True, remove_columns=[\"id\",\"tokens\",\"ner_tags\"]),\n    \"validation_no_diac\": all_splits[\"validation_no_diac\"].map(tokenize_and_align, batched=True, remove_columns=[\"id\",\"tokens\",\"ner_tags\"]),\n    \"test_no_diac\": all_splits[\"test_no_diac\"].map(tokenize_and_align, batched=True, remove_columns=[\"id\",\"tokens\",\"ner_tags\"]),\n    \"validation_cs\": all_splits[\"validation_cs\"].map(tokenize_and_align, batched=True, remove_columns=[\"id\",\"tokens\",\"ner_tags\"]),\n    \"test_cs\": all_splits[\"test_cs\"].map(tokenize_and_align, batched=True, remove_columns=[\"id\",\"tokens\",\"ner_tags\"]),\n})\ntok_ds","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Data collator and evaluation metric","metadata":{}},{"cell_type":"code","source":"collator = DataCollatorForTokenClassification(tokenizer=tok)\nmetric = evaluate.load(\"seqeval\")\n\ndef compute_metrics(eval_pred):\n    logits, labels = eval_pred\n    preds = np.argmax(logits, axis=-1)\n\n    true_preds, true_labels = [], []\n    for p_row, l_row in zip(preds, labels):\n        preds_i, labels_i = [], []\n        for p, l in zip(p_row, l_row):\n            if l != -100:\n                preds_i.append(id2label[p])\n                labels_i.append(id2label[l])\n        true_preds.append(preds_i)\n        true_labels.append(labels_i)\n    return metric.compute(predictions=true_preds, references=true_labels)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Model A - Full fine-tune (`xlm-roberta-base`)","metadata":{}},{"cell_type":"code","source":"model = AutoModelForTokenClassification.from_pretrained(\n    \"xlm-roberta-base\",\n    num_labels=len(label_names),\n    id2label=id2label,\n    label2id=label2id\n)\n\nargs = TrainingArguments(\n    output_dir=\"/kaggle/working/yoruba_ner_xlmr\",\n    eval_strategy=\"epoch\",\n    save_strategy=\"no\",\n    logging_strategy=\"epoch\",\n    learning_rate=2e-5,\n    per_device_train_batch_size=8,\n    per_device_eval_batch_size=8,\n    num_train_epochs=5,\n    weight_decay=0.01,\n    fp16=True,\n    load_best_model_at_end=False,\n    report_to=\"none\",\n    seed=SEED,\n    save_total_limit=1,\n    save_only_model=True\n)\n\ntrainer = Trainer(\n    model=model,\n    args=args,\n    train_dataset=tok_ds[\"train\"],\n    eval_dataset=tok_ds[\"validation\"],\n    tokenizer=tok,\n    data_collator=collator,\n    compute_metrics=compute_metrics,\n)\n\ntrain_result = trainer.train()\ntrainer.save_model(\"/kaggle/working/yoruba_ner_xlmr/best\")\n\nval_metrics = trainer.evaluate(eval_dataset=tok_ds[\"validation\"])\nval_metrics","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Robustness evaluation: clean, no-diacritics, code-switch","metadata":{}},{"cell_type":"code","source":"def eval_split(name, dataset):\n    out = trainer.evaluate(eval_dataset=dataset)\n    return {\n        \"split\": name,\n        \"precision\": out[\"eval_overall_precision\"],\n        \"recall\": out[\"eval_overall_recall\"],\n        \"f1\": out[\"eval_overall_f1\"],\n        \"accuracy\": out[\"eval_overall_accuracy\"],\n        \"loss\": out[\"eval_loss\"],\n    }\n\nrows = []\nrows.append(eval_split(\"test_clean\", tok_ds[\"test\"]))\nrows.append(eval_split(\"test_no_diacritics\", tok_ds[\"test_no_diac\"]))\nrows.append(eval_split(\"test_codeswitch\", tok_ds[\"test_cs\"]))\n\nresults_df = pd.DataFrame(rows).sort_values(\"split\").reset_index(drop=True)\ndisplay(results_df)\n\ncsv_path = \"/kaggle/working/yoruba_ner_xlmr/robustness_results.csv\"\nresults_df.to_csv(csv_path, index=False)\nprint(\"Saved:\", csv_path)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Per-entity F1 for full fine-tune","metadata":{}},{"cell_type":"code","source":"def per_entity_report(dataset):\n    rep = trainer.evaluate(eval_dataset=dataset)\n    ents = [\"DATE\",\"LOC\",\"ORG\",\"PER\"]\n    return {e: rep[f\"eval_{e}\"][\"f1\"] for e in ents}\n\nprint(\"per-entity F1 (clean):\", per_entity_report(tok_ds[\"test\"]))\nprint(\"per-entity F1 (no diacritics):\", per_entity_report(tok_ds[\"test_no_diac\"]))\nprint(\"per-entity F1 (codeswitch):\", per_entity_report(tok_ds[\"test_cs\"]))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Model B - LoRA (parameter-efficient)","metadata":{}},{"cell_type":"code","source":"base_model_ckpt = \"xlm-roberta-base\"\nlora_cfg = LoraConfig(\n    task_type=TaskType.TOKEN_CLS,\n    r=8,\n    lora_alpha=16,\n    lora_dropout=0.1,\n    bias=\"none\",\n    target_modules=[\"query\",\"key\",\"value\",\"output.dense\"]\n)\n\nlora_model = AutoModelForTokenClassification.from_pretrained(\n    base_model_ckpt,\n    num_labels=len(label_names),\n    id2label=id2label,\n    label2id=label2id\n)\nlora_model = get_peft_model(lora_model, lora_cfg)\nlora_model.print_trainable_parameters()\n\nlora_args = TrainingArguments(\n    output_dir=\"/kaggle/working/yoruba_ner_xlmr_lora\",\n    eval_strategy=\"epoch\",\n    save_strategy=\"no\",\n    logging_strategy=\"epoch\",\n    learning_rate=2e-4,\n    per_device_train_batch_size=8,\n    per_device_eval_batch_size=8,\n    num_train_epochs=5,\n    weight_decay=0.0,\n    fp16=True,\n    load_best_model_at_end=False,\n    report_to=\"none\",\n    seed=SEED,\n    save_total_limit=1,\n    save_only_model=True\n)\n\nlora_trainer = Trainer(\n    model=lora_model,\n    args=lora_args,\n    train_dataset=tok_ds[\"train\"],\n    eval_dataset=tok_ds[\"validation\"],\n    tokenizer=tok,\n    data_collator=collator,\n    compute_metrics=compute_metrics,\n)\n\nlora_trainer.train()\nlora_trainer.save_model(\"/kaggle/working/yoruba_ner_xlmr_lora/best\")\nlora_val = lora_trainer.evaluate(eval_dataset=tok_ds[\"validation\"])\nlora_val","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Compare full vs LoRA on all conditions","metadata":{}},{"cell_type":"code","source":"def eval_with(tr, name, dataset, split_name):\n    out = tr.evaluate(eval_dataset=dataset)\n    return {\n        \"model\": name, \"split\": split_name,\n        \"precision\": out[\"eval_overall_precision\"],\n        \"recall\": out[\"eval_overall_recall\"],\n        \"f1\": out[\"eval_overall_f1\"],\n        \"accuracy\": out[\"eval_overall_accuracy\"],\n        \"loss\": out[\"eval_loss\"],\n    }\n\nrows = []\n# full fine-tune\nrows += [\n    eval_with(trainer, \"xlmr_full\", tok_ds[\"test\"], \"test_clean\"),\n    eval_with(trainer, \"xlmr_full\", tok_ds[\"test_no_diac\"], \"test_no_diacritics\"),\n    eval_with(trainer, \"xlmr_full\", tok_ds[\"test_cs\"], \"test_codeswitch\"),\n]\n# LoRA\nrows += [\n    eval_with(lora_trainer, \"xlmr_lora\", tok_ds[\"test\"], \"test_clean\"),\n    eval_with(lora_trainer, \"xlmr_lora\", tok_ds[\"test_no_diac\"], \"test_no_diacritics\"),\n    eval_with(lora_trainer, \"xlmr_lora\", tok_ds[\"test_cs\"], \"test_codeswitch\"),\n]\n\ncomp = pd.DataFrame(rows)\ndisplay(comp)\n\nout_path = \"/kaggle/working/yoruba_ner_xlmr_lora/robustness_compare.csv\"\ncomp.to_csv(out_path, index=False)\nprint(\"Saved:\", out_path)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Model C - Mixed training (concatenate original + no-diac train)","metadata":{}},{"cell_type":"code","source":"feats = Features({\n    \"id\": Value(\"string\"),\n    \"tokens\": Sequence(Value(\"string\")),\n    \"ner_tags\": Sequence(ClassLabel(names=label_names)),\n})\n\ndef make_no_diac_split(split_ds):\n    rows = []\n    for ex in split_ds:\n        rows.append({\n            \"id\": ex[\"id\"],\n            \"tokens\": [strip_diacritics(t) for t in ex[\"tokens\"]],\n            \"ner_tags\": ex[\"ner_tags\"],\n        })\n    return Dataset.from_list(rows, features=feats)\n\ntrain_no_diac = make_no_diac_split(all_splits[\"train\"])\nprint(train_no_diac.features)\n\nmixed_train_raw = concatenate_datasets([all_splits[\"train\"], train_no_diac]).shuffle(seed=SEED)\nlen(all_splits[\"train\"]), len(train_no_diac), len(mixed_train_raw)\n\nmixed_train_tok = mixed_train_raw.map(\n    tokenize_and_align,\n    batched=True,\n    remove_columns=[\"id\",\"tokens\",\"ner_tags\"]\n)\n\nmixed_args = TrainingArguments(\n    output_dir=\"/kaggle/working/yoruba_ner_xlmr_mixed\",\n    eval_strategy=\"epoch\",\n    save_strategy=\"no\",\n    logging_strategy=\"epoch\",\n    learning_rate=2e-5,\n    warmup_ratio=0.1,\n    per_device_train_batch_size=8,\n    per_device_eval_batch_size=8,\n    num_train_epochs=5,\n    weight_decay=0.01,\n    fp16=True,\n    load_best_model_at_end=False,\n    report_to=\"none\",\n    seed=SEED,\n    save_total_limit=1,\n    save_only_model=True\n)\n\nmixed_model = AutoModelForTokenClassification.from_pretrained(\n    \"xlm-roberta-base\",\n    num_labels=len(label_names),\n    id2label=id2label,\n    label2id=label2id\n)\n\nmixed_trainer = Trainer(\n    model=mixed_model,\n    args=mixed_args,\n    train_dataset=mixed_train_tok,\n    eval_dataset=tok_ds[\"validation\"],\n    tokenizer=tok,\n    data_collator=collator,\n    compute_metrics=compute_metrics,\n)\n\nmixed_trainer.train()\nmixed_trainer.save_model(\"/kaggle/working/yoruba_ner_xlmr_mixed/final\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Evaluate mixed model on all test conditions + save tables and figures","metadata":{}},{"cell_type":"code","source":"def eval_with_table(tr, split_name, dataset):\n    out = tr.evaluate(eval_dataset=dataset)\n    return {\n        \"split\": split_name,\n        \"precision\": out[\"eval_overall_precision\"],\n        \"recall\": out[\"eval_overall_recall\"],\n        \"f1\": out[\"eval_overall_f1\"],\n        \"accuracy\": out[\"eval_overall_accuracy\"],\n        \"loss\": out[\"eval_loss\"]\n    }\n\nrows = []\nrows.append(eval_with_table(mixed_trainer, \"test_clean\", tok_ds[\"test\"]))\nrows.append(eval_with_table(mixed_trainer, \"test_no_diacritics\", tok_ds[\"test_no_diac\"]))\nrows.append(eval_with_table(mixed_trainer, \"test_codeswitch\", tok_ds[\"test_cs\"]))\n\nmixed_results = pd.DataFrame(rows)\nmixed_results.to_csv(\"/kaggle/working/yoruba_ner_xlmr_mixed/mixed_robustness_results.csv\", index=False)\ndisplay(mixed_results)\n\ndef per_entity(tr, dataset):\n    rep = tr.evaluate(eval_dataset=dataset)\n    ents = [\"DATE\",\"LOC\",\"ORG\",\"PER\"]\n    return {e: rep[f\"eval_{e}\"][\"f1\"] for e in ents}\n\n# baseline full fine-tune\nfull_clean = per_entity(trainer, tok_ds[\"test\"])\nfull_nodiac = per_entity(trainer, tok_ds[\"test_no_diac\"])\nfull_cs    = per_entity(trainer, tok_ds[\"test_cs\"])\n\n# mixed model\nmix_clean  = per_entity(mixed_trainer, tok_ds[\"test\"])\nmix_nodiac = per_entity(mixed_trainer, tok_ds[\"test_no_diac\"])\nmix_cs     = per_entity(mixed_trainer, tok_ds[\"test_cs\"])\n\ndef tidy(model_name, cond, d):\n    return pd.DataFrame([{\"model\": model_name, \"cond\": cond, \"entity\": k, \"f1\": v} for k,v in d.items()])\n\nper_ent_df = pd.concat([\n    tidy(\"full\",\"clean\",full_clean), tidy(\"full\",\"no_diac\",full_nodiac), tidy(\"full\",\"codeswitch\",full_cs),\n    tidy(\"mixed\",\"clean\",mix_clean), tidy(\"mixed\",\"no_diac\",mix_nodiac), tidy(\"mixed\",\"codeswitch\",mix_cs),\n], ignore_index=True)\nper_ent_df.to_csv(\"/kaggle/working/yoruba_ner_xlmr/per_entity_f1.csv\", index=False)\nper_ent_df.head()\n\n# Figures\ndef bar_drop(df, model_name, out_png):\n    base = df[(df.model==model_name) & (df.cond==\"clean\")].set_index(\"entity\")[\"f1\"]\n    nd   = df[(df.model==model_name) & (df.cond==\"no_diac\")].set_index(\"entity\")[\"f1\"]\n    cs   = df[(df.model==model_name) & (df.cond==\"codeswitch\")].set_index(\"entity\")[\"f1\"]\n\n    entities = base.index.tolist()\n    x = range(len(entities))\n\n    plt.figure(figsize=(7,4.5))\n    plt.bar([i-0.25 for i in x], base.values, width=0.25, label=\"clean\")\n    plt.bar(x, nd.values, width=0.25, label=\"no_diac\")\n    plt.bar([i+0.25 for i in x], cs.values, width=0.25, label=\"codeswitch\")\n    plt.xticks(list(x), entities)\n    plt.ylabel(\"F1\")\n    plt.title(f\"Per-entity F1 by condition — {model_name}\")\n    plt.legend()\n    plt.tight_layout()\n    plt.savefig(out_png, dpi=160)\n    plt.show()\n\nbar_drop(per_ent_df, \"full\", \"/kaggle/working/yoruba_ner_xlmr/fig_full_per_entity.png\")\nbar_drop(per_ent_df, \"mixed\", \"/kaggle/working/yoruba_ner_xlmr_mixed/fig_mixed_per_entity.png\")","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}